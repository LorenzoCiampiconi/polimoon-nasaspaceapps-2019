{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Meteorite_Landings.csv\")\n",
    "df = df.drop(['GeoLocation'], axis=1)\n",
    "df = df.rename(columns={'year': 'date'})\n",
    "oldIdx = df[df['date'].str.slice(start=6, stop=10).astype(float) <1700].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass (g)</th>\n",
       "      <th>fall</th>\n",
       "      <th>date</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Castrovillari</td>\n",
       "      <td>5295</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1583 12:00:00 AM</td>\n",
       "      <td>39.80000</td>\n",
       "      <td>16.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Elbogen</td>\n",
       "      <td>7823</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IID</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/24/1399 12:00:00 AM</td>\n",
       "      <td>50.18333</td>\n",
       "      <td>12.73333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Ensisheim</td>\n",
       "      <td>10039</td>\n",
       "      <td>Valid</td>\n",
       "      <td>LL6</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/23/1491 12:00:00 AM</td>\n",
       "      <td>47.86667</td>\n",
       "      <td>7.35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>FÃ¼nen</td>\n",
       "      <td>10838</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1654 12:00:00 AM</td>\n",
       "      <td>55.33333</td>\n",
       "      <td>10.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Hatford</td>\n",
       "      <td>11855</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1628 12:00:00 AM</td>\n",
       "      <td>51.65000</td>\n",
       "      <td>-1.51667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>12069</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1621 12:00:00 AM</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>75.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Minamino</td>\n",
       "      <td>16692</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1632 12:00:00 AM</td>\n",
       "      <td>35.07833</td>\n",
       "      <td>136.93333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Mount Vaisi</td>\n",
       "      <td>16805</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1637 12:00:00 AM</td>\n",
       "      <td>44.08333</td>\n",
       "      <td>6.86667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Narni</td>\n",
       "      <td>16914</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/27/0920 12:00:00 AM</td>\n",
       "      <td>42.51667</td>\n",
       "      <td>12.51667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Nogata</td>\n",
       "      <td>16988</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>472.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/28/0860 12:00:00 AM</td>\n",
       "      <td>33.72500</td>\n",
       "      <td>130.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Novy-Ergi</td>\n",
       "      <td>17934</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1662 12:00:00 AM</td>\n",
       "      <td>58.55000</td>\n",
       "      <td>31.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Oliva-Gandia</td>\n",
       "      <td>18012</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/22/1519 12:00:00 AM</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>-0.03333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Ortenau</td>\n",
       "      <td>18033</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1671 12:00:00 AM</td>\n",
       "      <td>48.50000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>Rivolta de Bassi</td>\n",
       "      <td>22614</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>103.3</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/23/1490 12:00:00 AM</td>\n",
       "      <td>45.48333</td>\n",
       "      <td>9.51667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Sagan</td>\n",
       "      <td>22796</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1636 12:00:00 AM</td>\n",
       "      <td>51.53333</td>\n",
       "      <td>14.88333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Sasagase</td>\n",
       "      <td>23187</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H</td>\n",
       "      <td>695.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1688 12:00:00 AM</td>\n",
       "      <td>34.71667</td>\n",
       "      <td>137.78333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Stolzenau</td>\n",
       "      <td>23726</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1647 12:00:00 AM</td>\n",
       "      <td>52.53333</td>\n",
       "      <td>9.05000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Stretchleigh</td>\n",
       "      <td>23732</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1623 12:00:00 AM</td>\n",
       "      <td>50.38333</td>\n",
       "      <td>-3.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Vago</td>\n",
       "      <td>24143</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1668 12:00:00 AM</td>\n",
       "      <td>45.41667</td>\n",
       "      <td>11.13333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Valdinoce</td>\n",
       "      <td>24146</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Stone-uncl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>12/23/1495 12:00:00 AM</td>\n",
       "      <td>44.06667</td>\n",
       "      <td>12.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>Campo del Cielo</td>\n",
       "      <td>5247</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IAB-MG</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>12/22/1575 12:00:00 AM</td>\n",
       "      <td>-27.46667</td>\n",
       "      <td>-60.58333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>Morito</td>\n",
       "      <td>16745</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IIIAB</td>\n",
       "      <td>10100000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1600 12:00:00 AM</td>\n",
       "      <td>27.05000</td>\n",
       "      <td>-105.43333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name     id nametype      recclass    mass (g)   fall  \\\n",
       "174       Castrovillari   5295    Valid    Stone-uncl     15000.0   Fell   \n",
       "278             Elbogen   7823    Valid     Iron, IID    107000.0   Fell   \n",
       "283           Ensisheim  10039    Valid           LL6    127000.0   Fell   \n",
       "312               FÃ¼nen  10838    Valid    Stone-uncl         NaN   Fell   \n",
       "369             Hatford  11855    Valid    Stone-uncl     29000.0   Fell   \n",
       "410           Jalandhar  12069    Valid          Iron      1967.0   Fell   \n",
       "627            Minamino  16692    Valid             L      1040.0   Fell   \n",
       "657         Mount Vaisi  16805    Valid    Stone-uncl     17000.0   Fell   \n",
       "679               Narni  16914    Valid    Stone-uncl         NaN   Fell   \n",
       "704              Nogata  16988    Valid            L6       472.0   Fell   \n",
       "710           Novy-Ergi  17934    Valid    Stone-uncl         NaN   Fell   \n",
       "730        Oliva-Gandia  18012    Valid    Stone-uncl         NaN   Fell   \n",
       "737             Ortenau  18033    Valid    Stone-uncl      4500.0   Fell   \n",
       "856    Rivolta de Bassi  22614    Valid    Stone-uncl       103.3   Fell   \n",
       "869               Sagan  22796    Valid    Stone-uncl         NaN   Fell   \n",
       "887            Sasagase  23187    Valid             H       695.0   Fell   \n",
       "957           Stolzenau  23726    Valid    Stone-uncl         NaN   Fell   \n",
       "960        Stretchleigh  23732    Valid    Stone-uncl     10400.0   Fell   \n",
       "1040               Vago  24143    Valid            H6        40.0   Fell   \n",
       "1043          Valdinoce  24146    Valid    Stone-uncl         NaN   Fell   \n",
       "5365    Campo del Cielo   5247    Valid  Iron, IAB-MG  50000000.0  Found   \n",
       "26174            Morito  16745    Valid   Iron, IIIAB  10100000.0  Found   \n",
       "\n",
       "                         date    reclat    reclong  \n",
       "174    01/01/1583 12:00:00 AM  39.80000   16.20000  \n",
       "278    12/24/1399 12:00:00 AM  50.18333   12.73333  \n",
       "283    12/23/1491 12:00:00 AM  47.86667    7.35000  \n",
       "312    01/01/1654 12:00:00 AM  55.33333   10.33333  \n",
       "369    01/01/1628 12:00:00 AM  51.65000   -1.51667  \n",
       "410    01/01/1621 12:00:00 AM  31.00000   75.00000  \n",
       "627    01/01/1632 12:00:00 AM  35.07833  136.93333  \n",
       "657    01/01/1637 12:00:00 AM  44.08333    6.86667  \n",
       "679    12/27/0920 12:00:00 AM  42.51667   12.51667  \n",
       "704    12/28/0860 12:00:00 AM  33.72500  130.75000  \n",
       "710    01/01/1662 12:00:00 AM  58.55000   31.33333  \n",
       "730    12/22/1519 12:00:00 AM  39.00000   -0.03333  \n",
       "737    01/01/1671 12:00:00 AM  48.50000    8.00000  \n",
       "856    12/23/1490 12:00:00 AM  45.48333    9.51667  \n",
       "869    01/01/1636 12:00:00 AM  51.53333   14.88333  \n",
       "887    01/01/1688 12:00:00 AM  34.71667  137.78333  \n",
       "957    01/01/1647 12:00:00 AM  52.53333    9.05000  \n",
       "960    01/01/1623 12:00:00 AM  50.38333   -3.95000  \n",
       "1040   01/01/1668 12:00:00 AM  45.41667   11.13333  \n",
       "1043   12/23/1495 12:00:00 AM  44.06667   12.10000  \n",
       "5365   12/22/1575 12:00:00 AM -27.46667  -60.58333  \n",
       "26174  01/01/1600 12:00:00 AM  27.05000 -105.43333  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[oldIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(oldIdx)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass (g)</th>\n",
       "      <th>fall</th>\n",
       "      <th>date</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880-01-01</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abee</td>\n",
       "      <td>6</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1952-01-01</td>\n",
       "      <td>54.21667</td>\n",
       "      <td>-113.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acapulco</td>\n",
       "      <td>10</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>16.88333</td>\n",
       "      <td>-99.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achiras</td>\n",
       "      <td>370</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>-33.16667</td>\n",
       "      <td>-64.95000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   id nametype     recclass  mass (g)  fall        date    reclat  \\\n",
       "0    Aachen    1    Valid           L5      21.0  Fell  1880-01-01  50.77500   \n",
       "1    Aarhus    2    Valid           H6     720.0  Fell  1951-01-01  56.18333   \n",
       "2      Abee    6    Valid          EH4  107000.0  Fell  1952-01-01  54.21667   \n",
       "3  Acapulco   10    Valid  Acapulcoite    1914.0  Fell  1976-01-01  16.88333   \n",
       "4   Achiras  370    Valid           L6     780.0  Fell  1902-01-01 -33.16667   \n",
       "\n",
       "     reclong  \n",
       "0    6.08333  \n",
       "1   10.23333  \n",
       "2 -113.00000  \n",
       "3  -99.90000  \n",
       "4  -64.95000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass (g)</th>\n",
       "      <th>fall</th>\n",
       "      <th>date</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45694</td>\n",
       "      <td>45694.000000</td>\n",
       "      <td>45694</td>\n",
       "      <td>45694</td>\n",
       "      <td>4.557000e+04</td>\n",
       "      <td>45694</td>\n",
       "      <td>45403</td>\n",
       "      <td>38379.000000</td>\n",
       "      <td>38379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>45694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Lewis Cliff 85317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45619</td>\n",
       "      <td>8284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44607</td>\n",
       "      <td>3323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26894.679761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.195670e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-39.168483</td>\n",
       "      <td>61.097057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16862.720822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.231189e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.350368</td>\n",
       "      <td>80.653885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.366670</td>\n",
       "      <td>-165.433330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12690.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.200000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-76.714700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24273.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.259000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.500000</td>\n",
       "      <td>35.666670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40664.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.020075e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>157.166670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57458.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.166670</td>\n",
       "      <td>354.473330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name            id nametype recclass      mass (g)  \\\n",
       "count               45694  45694.000000    45694    45694  4.557000e+04   \n",
       "unique              45694           NaN        2      466           NaN   \n",
       "top     Lewis Cliff 85317           NaN    Valid       L6           NaN   \n",
       "freq                    1           NaN    45619     8284           NaN   \n",
       "mean                  NaN  26894.679761      NaN      NaN  1.195670e+04   \n",
       "std                   NaN  16862.720822      NaN      NaN  5.231189e+05   \n",
       "min                   NaN      1.000000      NaN      NaN  0.000000e+00   \n",
       "25%                   NaN  12690.250000      NaN      NaN  7.200000e+00   \n",
       "50%                   NaN  24273.500000      NaN      NaN  3.259000e+01   \n",
       "75%                   NaN  40664.750000      NaN      NaN  2.020075e+02   \n",
       "max                   NaN  57458.000000      NaN      NaN  6.000000e+07   \n",
       "\n",
       "         fall        date        reclat       reclong  \n",
       "count   45694       45403  38379.000000  38379.000000  \n",
       "unique      2         243           NaN           NaN  \n",
       "top     Found  2003-01-01           NaN           NaN  \n",
       "freq    44607        3323           NaN           NaN  \n",
       "mean      NaN         NaN    -39.168483     61.097057  \n",
       "std       NaN         NaN     46.350368     80.653885  \n",
       "min       NaN         NaN    -87.366670   -165.433330  \n",
       "25%       NaN         NaN    -76.714700      0.000000  \n",
       "50%       NaN         NaN    -71.500000     35.666670  \n",
       "75%       NaN         NaN      0.000000    157.166670  \n",
       "max       NaN         NaN     81.166670    354.473330  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import hmean\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "import numbers\n",
    "\n",
    "\n",
    "def weighted_hamming(data):\n",
    "    \"\"\" Compute weighted hamming distance on categorical variables. For one variable, it is equal to 1 if\n",
    "        the values between point A and point B are different, else it is equal the relative frequency of the\n",
    "        distribution of the value across the variable. For multiple variables, the harmonic mean is computed\n",
    "        up to a constant factor.\n",
    "\n",
    "        @params:\n",
    "            - data = a pandas data frame of categorical variables\n",
    "\n",
    "        @returns:\n",
    "            - distance_matrix = a distance matrix with pairwise distance for all attributes\n",
    "    \"\"\"\n",
    "    categories_dist = []\n",
    "    \n",
    "    for category in data:\n",
    "        X = pd.get_dummies(data[category])\n",
    "        X_mean = X * X.mean()\n",
    "        X_dot = X_mean.dot(X.transpose())\n",
    "        X_np = np.asarray(X_dot.replace(0,1,inplace=False))\n",
    "        categories_dist.append(X_np)\n",
    "    categories_dist = np.array(categories_dist)\n",
    "    distances = hmean(categories_dist, axis=0)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def distance_matrix(data, numeric_distance = \"euclidean\", categorical_distance = \"jaccard\"):\n",
    "    \"\"\" Compute the pairwise distance attribute by attribute in order to account for different variables type:\n",
    "        - Continuous\n",
    "        - Categorical\n",
    "        For ordinal values, provide a numerical representation taking the order into account.\n",
    "        Categorical variables are transformed into a set of binary ones.\n",
    "        If both continuous and categorical distance are provided, a Gower-like distance is computed and the numeric\n",
    "        variables are all normalized in the process.\n",
    "        If there are missing values, the mean is computed for numerical attributes and the mode for categorical ones.\n",
    "        \n",
    "        Note: If weighted-hamming distance is chosen, the computation time increases a lot since it is not coded in C \n",
    "        like other distance metrics provided by scipy.\n",
    "\n",
    "        @params:\n",
    "            - data                  = pandas dataframe to compute distances on.\n",
    "            - numeric_distances     = the metric to apply to continuous attributes.\n",
    "                                      \"euclidean\" and \"cityblock\" available.\n",
    "                                      Default = \"euclidean\"\n",
    "            - categorical_distances = the metric to apply to binary attributes.\n",
    "                                      \"jaccard\", \"hamming\", \"weighted-hamming\" and \"euclidean\"\n",
    "                                      available. Default = \"jaccard\"\n",
    "\n",
    "        @returns:\n",
    "            - the distance matrix\n",
    "    \"\"\"\n",
    "    possible_continuous_distances = [\"euclidean\", \"cityblock\"]\n",
    "    possible_binary_distances = [\"euclidean\", \"jaccard\", \"hamming\", \"weighted-hamming\"]\n",
    "    number_of_variables = data.shape[1]\n",
    "    number_of_observations = data.shape[0]\n",
    "\n",
    "    # Get the type of each attribute (Numeric or categorical)\n",
    "    is_numeric = [all(isinstance(n, numbers.Number) for n in data.iloc[:, i]) for i, x in enumerate(data)]\n",
    "    is_all_numeric = sum(is_numeric) == len(is_numeric)\n",
    "    is_all_categorical = sum(is_numeric) == 0\n",
    "    is_mixed_type = not is_all_categorical and not is_all_numeric\n",
    "\n",
    "    # Check the content of the distances parameter\n",
    "    if numeric_distance not in possible_continuous_distances:\n",
    "        print(\"The continuous distance \" + numeric_distance + \" is not supported.\")\n",
    "        return None\n",
    "    elif categorical_distance not in possible_binary_distances:\n",
    "        print(\"The binary distance \" + categorical_distance + \" is not supported.\")\n",
    "        return None\n",
    "\n",
    "    # Separate the data frame into categorical and numeric attributes and normalize numeric data\n",
    "    if is_mixed_type:\n",
    "        number_of_numeric_var = sum(is_numeric)\n",
    "        number_of_categorical_var = number_of_variables - number_of_numeric_var\n",
    "        data_numeric = data.iloc[:, is_numeric]\n",
    "        data_numeric = (data_numeric - data_numeric.mean()) / (data_numeric.max() - data_numeric.min())\n",
    "        data_categorical = data.iloc[:, [not x for x in is_numeric]]\n",
    "\n",
    "    # Replace missing values with column mean for numeric values and mode for categorical ones. With the mode, it\n",
    "    # triggers a warning: \"SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "    # but the value are properly replaced\n",
    "    if is_mixed_type:\n",
    "        data_numeric.fillna(data_numeric.mean(), inplace=True)\n",
    "        for x in data_categorical:\n",
    "            data_categorical[x].fillna(data_categorical[x].mode()[0], inplace=True)\n",
    "    elif is_all_numeric:\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "    else:\n",
    "        for x in data:\n",
    "            data[x].fillna(data[x].mode()[0], inplace=True)\n",
    "\n",
    "    # \"Dummifies\" categorical variables in place\n",
    "    if not is_all_numeric and not (categorical_distance == 'hamming' or categorical_distance == 'weighted-hamming'):\n",
    "        if is_mixed_type:\n",
    "            data_categorical = pd.get_dummies(data_categorical)\n",
    "        else:\n",
    "            data = pd.get_dummies(data)\n",
    "    elif not is_all_numeric and categorical_distance == 'hamming':\n",
    "        if is_mixed_type:\n",
    "            data_categorical = pd.DataFrame([pd.factorize(data_categorical[x])[0] for x in data_categorical]).transpose()\n",
    "        else:\n",
    "            data = pd.DataFrame([pd.factorize(data[x])[0] for x in data]).transpose()\n",
    "\n",
    "    if is_all_numeric:\n",
    "        result_matrix = cdist(data, data, metric=numeric_distance)\n",
    "    elif is_all_categorical:\n",
    "        if categorical_distance == \"weighted-hamming\":\n",
    "            result_matrix = weighted_hamming(data)\n",
    "        else:\n",
    "            result_matrix = cdist(data, data, metric=categorical_distance)\n",
    "    else:\n",
    "        result_numeric = cdist(data_numeric, data_numeric, metric=numeric_distance)\n",
    "        if categorical_distance == \"weighted-hamming\":\n",
    "            result_categorical = weighted_hamming(data_categorical)\n",
    "        else:\n",
    "            result_categorical = cdist(data_categorical, data_categorical, metric=categorical_distance)\n",
    "        result_matrix = np.array([[1.0*(result_numeric[i, j] * number_of_numeric_var + result_categorical[i, j] *\n",
    "                               number_of_categorical_var) / number_of_variables for j in range(number_of_observations)] for i in range(number_of_observations)])\n",
    "\n",
    "    # Fill the diagonal with NaN values\n",
    "    np.fill_diagonal(result_matrix, np.nan)\n",
    "\n",
    "    return pd.DataFrame(result_matrix)\n",
    "\n",
    "\n",
    "def knn_impute(target, attributes, k_neighbors, aggregation_method=\"mean\", numeric_distance=\"euclidean\",\n",
    "               categorical_distance=\"jaccard\", missing_neighbors_threshold = 0.5):\n",
    "    \"\"\" Replace the missing values within the target variable based on its k nearest neighbors identified with the\n",
    "        attributes variables. If more than 50% of its neighbors are also missing values, the value is not modified and\n",
    "        remains missing. If there is a problem in the parameters provided, returns None.\n",
    "        If to many neighbors also have missing values, leave the missing value of interest unchanged.\n",
    "\n",
    "        @params:\n",
    "            - target                        = a vector of n values with missing values that you want to impute. The length has\n",
    "                                              to be at least n = 3.\n",
    "            - attributes                    = a data frame of attributes with n rows to match the target variable\n",
    "            - k_neighbors                   = the number of neighbors to look at to impute the missing values. It has to be a\n",
    "                                              value between 1 and n.\n",
    "            - aggregation_method            = how to aggregate the values from the nearest neighbors (mean, median, mode)\n",
    "                                              Default = \"mean\"\n",
    "            - numeric_distances             = the metric to apply to continuous attributes.\n",
    "                                              \"euclidean\" and \"cityblock\" available.\n",
    "                                              Default = \"euclidean\"\n",
    "            - categorical_distances         = the metric to apply to binary attributes.\n",
    "                                              \"jaccard\", \"hamming\", \"weighted-hamming\" and \"euclidean\"\n",
    "                                              available. Default = \"jaccard\"\n",
    "            - missing_neighbors_threshold   = minimum of neighbors among the k ones that are not also missing to infer\n",
    "                                              the correct value. Default = 0.5\n",
    "\n",
    "        @returns:\n",
    "            target_completed        = the vector of target values with missing value replaced. If there is a problem\n",
    "                                      in the parameters, return None\n",
    "    \"\"\"\n",
    "\n",
    "    # Get useful variables\n",
    "    possible_aggregation_method = [\"mean\", \"median\", \"mode\"]\n",
    "    number_observations = len(target)\n",
    "    is_target_numeric = all(isinstance(n, numbers.Number) for n in target)\n",
    "\n",
    "    # Check for possible errors\n",
    "    if number_observations < 3:\n",
    "        print(\"Not enough observations.\")\n",
    "        return None\n",
    "    if attributes.shape[0] != number_observations:\n",
    "        print(\"The number of observations in the attributes variable is not matching the target variable length.\")\n",
    "        return None\n",
    "    if k_neighbors > number_observations or k_neighbors < 1:\n",
    "        print(\"The range of the number of neighbors is incorrect.\")\n",
    "        return None\n",
    "    if aggregation_method not in possible_aggregation_method:\n",
    "        print(\"The aggregation method is incorrect.\")\n",
    "        return None\n",
    "    if not is_target_numeric and aggregation_method != \"mode\":\n",
    "        print(\"The only method allowed for categorical target variable is the mode.\")\n",
    "        return None\n",
    "\n",
    "    # Make sure the data are in the right format\n",
    "    target = pd.DataFrame(target)\n",
    "    attributes = pd.DataFrame(attributes)\n",
    "\n",
    "    # Get the distance matrix and check whether no error was triggered when computing it\n",
    "    distances = distance_matrix(attributes, numeric_distance, categorical_distance)\n",
    "    if distances is None:\n",
    "        return None\n",
    "\n",
    "    # Get the closest points and compute the correct aggregation method\n",
    "    for i, value in enumerate(target.iloc[:, 0]):\n",
    "        if pd.isnull(value):\n",
    "            order = distances.iloc[i,:].values.argsort()[:k_neighbors]\n",
    "            closest_to_target = target.iloc[order, :]\n",
    "            missing_neighbors = [x for x  in closest_to_target.isnull().iloc[:, 0]]\n",
    "            # Compute the right aggregation method if at least more than 50% of the closest neighbors are not missing\n",
    "            if sum(missing_neighbors) >= missing_neighbors_threshold * k_neighbors:\n",
    "                continue\n",
    "            elif aggregation_method == \"mean\":\n",
    "                target.iloc[i] = np.ma.mean(np.ma.masked_array(closest_to_target,np.isnan(closest_to_target)))\n",
    "            elif aggregation_method == \"median\":\n",
    "                target.iloc[i] = np.ma.median(np.ma.masked_array(closest_to_target,np.isnan(closest_to_target)))\n",
    "            else:\n",
    "                target.iloc[i] = stats.mode(closest_to_target, nan_policy='omit')[0][0]\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
